{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model #3 for image prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from skimage import imread\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models,callbacks,metrics,backend\n",
    "import sys\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# sys.path.append(os.path.abspath(r'C:\\Users\\raulg\\Documents\\THEBRIDGE_DS\\0.-Repo_Git\\ml_alzheimer_class\\src'))\n",
    "sys.path.append(os.path.relpath('../src'))\n",
    "import utils as ut\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model aims to get a better accuracy, by adding datagen to the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1_train shape (34326, 32, 32, 1)\n",
      "x1_test shape (6058, 32, 32, 1)\n",
      "y1_train shape (34326,)\n",
      "y1_test shape (6058,)\n",
      "y1_train distribution: \n",
      " [[    0 10880]\n",
      " [    1  9520]\n",
      " [    2  8377]\n",
      " [    3  5549]]\n",
      "y1_test distribution: \n",
      " [[   0 1920]\n",
      " [   1 1680]\n",
      " [   2 1479]\n",
      " [   3  979]]\n",
      "x1_val shape (6866, 32, 32, 1)\n",
      "y1_val shape (6866,)\n",
      "y1_val distribution: \n",
      " [[   0 2176]\n",
      " [   1 1904]\n",
      " [   2 1676]\n",
      " [   3 1110]]\n"
     ]
    }
   ],
   "source": [
    "x1_train,x1_test,x1_val,y1_train,y1_test,y1_val = ut.img_images_load(val_set = True)\n",
    "# print(x1_train.shape)\n",
    "# print(x1_test.shape)\n",
    "# print(y1_train.shape)\n",
    "# print(y1_test.shape)\n",
    "# print(y1_val.shape)\n",
    "# unique_train, counts_train = np.unique(y1_train, return_counts=True)\n",
    "# unique_test, counts_test = np.unique(y1_test, return_counts=True)\n",
    "# unique_val, counts_val = np.unique(y1_val, return_counts=True)\n",
    "# print(np.asarray((unique_train, counts_train)).T)\n",
    "# print(np.asarray((unique_test, counts_test)).T)\n",
    "# print(np.asarray((unique_val, counts_val)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def recall_m(y_true, y_pred):\n",
    "#     # Convertir y_true a one-hot encoding\n",
    "#     y_true = backend.one_hot(backend.cast(y_true, 'int32'), num_classes=backend.shape(y_pred)[-1])\n",
    "#     # Calcular los verdaderos positivos\n",
    "#     true_positives = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)))\n",
    "#     # Calcular los posibles positivos\n",
    "#     possible_positives = backend.sum(backend.round(backend.clip(y_true, 0, 1)))\n",
    "#     # Calcular el recall\n",
    "#     recall = true_positives / (possible_positives + backend.epsilon())\n",
    "#     return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\raulg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\raulg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.3475 - loss: 1.3292 - val_accuracy: 0.3276 - val_loss: 1.3670\n",
      "Epoch 2/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.4010 - loss: 1.2369 - val_accuracy: 0.4308 - val_loss: 1.1906\n",
      "Epoch 3/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.4188 - loss: 1.1930 - val_accuracy: 0.4234 - val_loss: 1.2007\n",
      "Epoch 4/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.4394 - loss: 1.1687 - val_accuracy: 0.5020 - val_loss: 1.0772\n",
      "Epoch 5/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.4569 - loss: 1.1411 - val_accuracy: 0.5176 - val_loss: 1.0511\n",
      "Epoch 6/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.4704 - loss: 1.1068 - val_accuracy: 0.5706 - val_loss: 0.9390\n",
      "Epoch 7/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.4889 - loss: 1.0850 - val_accuracy: 0.5392 - val_loss: 0.9655\n",
      "Epoch 8/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.4994 - loss: 1.0484 - val_accuracy: 0.5714 - val_loss: 0.9049\n",
      "Epoch 9/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.5080 - loss: 1.0363 - val_accuracy: 0.5642 - val_loss: 0.8952\n",
      "Epoch 10/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.5291 - loss: 1.0076 - val_accuracy: 0.5770 - val_loss: 0.8723\n",
      "Epoch 11/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.5357 - loss: 0.9905 - val_accuracy: 0.5852 - val_loss: 0.8631\n",
      "Epoch 12/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.5354 - loss: 0.9866 - val_accuracy: 0.5819 - val_loss: 0.8907\n",
      "Epoch 13/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.5408 - loss: 0.9802 - val_accuracy: 0.5913 - val_loss: 0.8486\n",
      "Epoch 14/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.5422 - loss: 0.9671 - val_accuracy: 0.6022 - val_loss: 0.8346\n",
      "Epoch 15/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.5552 - loss: 0.9554 - val_accuracy: 0.5660 - val_loss: 0.8699\n",
      "Epoch 16/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 29ms/step - accuracy: 0.5621 - loss: 0.9393 - val_accuracy: 0.5936 - val_loss: 0.8213\n",
      "Epoch 17/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.5528 - loss: 0.9449 - val_accuracy: 0.6009 - val_loss: 0.8396\n",
      "Epoch 18/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.5623 - loss: 0.9250 - val_accuracy: 0.5829 - val_loss: 0.8942\n",
      "Epoch 19/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 0.5597 - loss: 0.9212 - val_accuracy: 0.6089 - val_loss: 0.8215\n",
      "Epoch 20/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.5667 - loss: 0.9190 - val_accuracy: 0.6098 - val_loss: 0.8207\n",
      "Epoch 21/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.5569 - loss: 0.9241 - val_accuracy: 0.5294 - val_loss: 0.8876\n",
      "Epoch 22/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.5589 - loss: 0.9231 - val_accuracy: 0.5936 - val_loss: 0.8194\n",
      "Epoch 23/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.5682 - loss: 0.9130 - val_accuracy: 0.5992 - val_loss: 0.8070\n",
      "Epoch 24/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.5762 - loss: 0.8982 - val_accuracy: 0.5990 - val_loss: 0.7991\n",
      "Epoch 25/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.5689 - loss: 0.9036 - val_accuracy: 0.6100 - val_loss: 0.8191\n",
      "Epoch 26/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.5760 - loss: 0.8910 - val_accuracy: 0.6206 - val_loss: 0.7789\n",
      "Epoch 27/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.5766 - loss: 0.8950 - val_accuracy: 0.6171 - val_loss: 0.7999\n",
      "Epoch 28/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.5742 - loss: 0.8901 - val_accuracy: 0.6161 - val_loss: 0.7761\n",
      "Epoch 29/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.5729 - loss: 0.8921 - val_accuracy: 0.6066 - val_loss: 0.7898\n",
      "Epoch 30/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.5736 - loss: 0.8844 - val_accuracy: 0.6156 - val_loss: 0.7726\n",
      "Epoch 31/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.5767 - loss: 0.8803 - val_accuracy: 0.6145 - val_loss: 0.8089\n",
      "Epoch 32/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.5801 - loss: 0.8817 - val_accuracy: 0.6031 - val_loss: 0.8102\n",
      "Epoch 33/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.5829 - loss: 0.8707 - val_accuracy: 0.6276 - val_loss: 0.7720\n",
      "Epoch 34/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.5826 - loss: 0.8733 - val_accuracy: 0.6022 - val_loss: 0.8404\n",
      "Epoch 35/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 0.5805 - loss: 0.8873 - val_accuracy: 0.6111 - val_loss: 0.8185\n",
      "Epoch 36/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.5847 - loss: 0.8673 - val_accuracy: 0.6295 - val_loss: 0.7767\n",
      "Epoch 37/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.5813 - loss: 0.8797 - val_accuracy: 0.6251 - val_loss: 0.7674\n",
      "Epoch 38/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.5889 - loss: 0.8619 - val_accuracy: 0.6365 - val_loss: 0.7495\n",
      "Epoch 39/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.5869 - loss: 0.8652 - val_accuracy: 0.6225 - val_loss: 0.7537\n",
      "Epoch 40/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.5907 - loss: 0.8614 - val_accuracy: 0.6372 - val_loss: 0.7675\n",
      "Epoch 41/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.5901 - loss: 0.8535 - val_accuracy: 0.6352 - val_loss: 0.7563\n",
      "Epoch 42/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.5939 - loss: 0.8533 - val_accuracy: 0.6181 - val_loss: 0.7642\n",
      "Epoch 43/70\n",
      "\u001b[1m430/430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.5948 - loss: 0.8519 - val_accuracy: 0.6304 - val_loss: 0.7727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x18368e1f1a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### COMP TIME: \n",
    "model3 = models.Sequential()\n",
    "model3.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
    "model3.add(layers.MaxPooling2D((2, 2)))\n",
    "model3.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model3.add(layers.MaxPooling2D((2, 2)))\n",
    "model3.add(layers.Flatten())\n",
    "\n",
    "# Capa densa con Dropout\n",
    "model3.add(layers.Dense(32, activation='relu'))\n",
    "model3.add(layers.Dropout(0.5))  # Dropout para reducir overfitting\n",
    "\n",
    "model3.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# Compilar el modelo\n",
    "model3.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', #sparse_categorical_crossentropy\n",
    "              metrics=['accuracy'])\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "# y1_train_encoded = label_encoder.fit_transform(y1_train)\n",
    "# y2_test_encoded = label_encoder.transform(y1_test)\n",
    "model3.fit(datagen.flow(x1_train,y1_train,batch_size=64),epochs=70,validation_data=(x1_val,y1_val), callbacks=callbacks.EarlyStopping(patience=5)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6383 - loss: 0.7821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7722964286804199, 0.6386595964431763]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(x1_test, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y1_pred = model3.predict(x1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, ..., 2, 1, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.6386596236381644)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y1_test, model3.predict(x1_test).argmax(axis=1),average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.76128591, 0.34763948, 0.1407212 , 0.00108225],\n",
       "       [0.2250342 , 0.46995708, 0.30430959, 0.0021645 ],\n",
       "       [0.01367989, 0.18240343, 0.5237467 , 0.01406926],\n",
       "       [0.        , 0.        , 0.03122252, 0.98268398]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y1_test, model3.predict(x1_test).argmax(axis=1),normalize='pred') #,normalize='pred'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
