{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model #2 for image prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from skimage import imread\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models,callbacks\n",
    "import sys\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# sys.path.append(os.path.abspath(r'C:\\Users\\raulg\\Documents\\THEBRIDGE_DS\\0.-Repo_Git\\ml_alzheimer_class\\src'))\n",
    "sys.path.append(os.path.relpath('../src'))\n",
    "import utils as ut\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and mix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model had some funny results - the validation results were quite bad (0.37 accuracy), but the test results reached a 0.87 in accuracy. I'll join the arrays and make a random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33984, 32, 32, 1)\n",
      "(6400, 32, 32, 1)\n",
      "(33984,)\n",
      "(6400,)\n"
     ]
    }
   ],
   "source": [
    "x1_train,x1_test,y1_train,y1_test = ut.img_images_load()\n",
    "print(x1_train.shape)\n",
    "print(x1_test.shape)\n",
    "print(y1_train.shape)\n",
    "print(y1_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15847860538827258"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6400/40384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1_train shape (34326, 32, 32, 1)\n",
      "x1_test shape (6058, 32, 32, 1)\n",
      "y1_train shape (34326,)\n",
      "y1_test shape (6058,)\n",
      "y1_train distribution: \n",
      " [[    0 10880]\n",
      " [    1  9520]\n",
      " [    2  8377]\n",
      " [    3  5549]]\n",
      "y1_test distribution: \n",
      " [[   0 1920]\n",
      " [   1 1680]\n",
      " [   2 1479]\n",
      " [   3  979]]\n"
     ]
    }
   ],
   "source": [
    "x1 = np.concatenate((x1_train,x1_test))\n",
    "y1 = np.concatenate((y1_train,y1_test))\n",
    "x1_train,x1_test,y1_train,y1_test = train_test_split(x1,y1,test_size=.15,stratify=y1,random_state=42)\n",
    "print('x1_train shape', x1_train.shape)\n",
    "print('x1_test shape', x1_test.shape)\n",
    "print('y1_train shape', y1_train.shape)\n",
    "print('y1_test shape', y1_test.shape)\n",
    "unique_train, counts_train = np.unique(y1_train, return_counts=True)\n",
    "unique_test, counts_test = np.unique(y1_test, return_counts=True)\n",
    "print('y1_train distribution: \\n',np.asarray((unique_train, counts_train)).T)\n",
    "print('y1_test distribution: \\n',np.asarray((unique_test, counts_test)).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0 10880]\n",
      " [    1  9520]\n",
      " [    2  8377]\n",
      " [    3  5549]]\n",
      "[[   0 1920]\n",
      " [   1 1680]\n",
      " [   2 1479]\n",
      " [   3  979]]\n"
     ]
    }
   ],
   "source": [
    "### Test whether stratify is ok\n",
    "unique_train, counts_train = np.unique(y1_train, return_counts=True)\n",
    "unique_test, counts_test = np.unique(y1_test, return_counts=True)\n",
    "print(np.asarray((unique_train, counts_train)).T)\n",
    "print(np.asarray((unique_test, counts_test)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy of the baseline model. I'll check the results now that the sets have been randomly mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\raulg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.3406 - loss: 1.3291 - val_accuracy: 0.5763 - val_loss: 1.0638\n",
      "Epoch 2/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.4370 - loss: 1.1318 - val_accuracy: 0.6129 - val_loss: 0.9307\n",
      "Epoch 3/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.4823 - loss: 1.0356 - val_accuracy: 0.6228 - val_loss: 0.8411\n",
      "Epoch 4/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.4998 - loss: 0.9816 - val_accuracy: 0.6579 - val_loss: 0.7825\n",
      "Epoch 5/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.5120 - loss: 0.9423 - val_accuracy: 0.6668 - val_loss: 0.7651\n",
      "Epoch 6/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.5231 - loss: 0.9280 - val_accuracy: 0.6899 - val_loss: 0.7234\n",
      "Epoch 7/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.5309 - loss: 0.8997 - val_accuracy: 0.7017 - val_loss: 0.6878\n",
      "Epoch 8/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.5644 - loss: 0.8863 - val_accuracy: 0.7121 - val_loss: 0.6760\n",
      "Epoch 9/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.5767 - loss: 0.8644 - val_accuracy: 0.7131 - val_loss: 0.6835\n",
      "Epoch 10/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.5895 - loss: 0.8461 - val_accuracy: 0.7250 - val_loss: 0.6531\n",
      "Epoch 11/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.5900 - loss: 0.8391 - val_accuracy: 0.7237 - val_loss: 0.6528\n",
      "Epoch 12/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.6002 - loss: 0.8213 - val_accuracy: 0.7068 - val_loss: 0.6424\n",
      "Epoch 13/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.6031 - loss: 0.8200 - val_accuracy: 0.7383 - val_loss: 0.6131\n",
      "Epoch 14/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6100 - loss: 0.8074 - val_accuracy: 0.7467 - val_loss: 0.6157\n",
      "Epoch 15/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6091 - loss: 0.7989 - val_accuracy: 0.7440 - val_loss: 0.6068\n",
      "Epoch 16/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.6213 - loss: 0.7853 - val_accuracy: 0.7467 - val_loss: 0.6011\n",
      "Epoch 17/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.6253 - loss: 0.7774 - val_accuracy: 0.7595 - val_loss: 0.5840\n",
      "Epoch 18/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6270 - loss: 0.7818 - val_accuracy: 0.7659 - val_loss: 0.5620\n",
      "Epoch 19/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6339 - loss: 0.7607 - val_accuracy: 0.7747 - val_loss: 0.5520\n",
      "Epoch 20/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.6387 - loss: 0.7628 - val_accuracy: 0.7757 - val_loss: 0.5534\n",
      "Epoch 21/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6353 - loss: 0.7661 - val_accuracy: 0.7651 - val_loss: 0.5498\n",
      "Epoch 22/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.6370 - loss: 0.7619 - val_accuracy: 0.7844 - val_loss: 0.5269\n",
      "Epoch 23/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6447 - loss: 0.7471 - val_accuracy: 0.7895 - val_loss: 0.5267\n",
      "Epoch 24/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6438 - loss: 0.7420 - val_accuracy: 0.7709 - val_loss: 0.5586\n",
      "Epoch 25/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.6461 - loss: 0.7428 - val_accuracy: 0.7913 - val_loss: 0.5282\n",
      "Epoch 26/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6458 - loss: 0.7372 - val_accuracy: 0.7983 - val_loss: 0.5096\n",
      "Epoch 27/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.6530 - loss: 0.7246 - val_accuracy: 0.7943 - val_loss: 0.5129\n",
      "Epoch 28/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6568 - loss: 0.7243 - val_accuracy: 0.7876 - val_loss: 0.5322\n",
      "Epoch 29/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6539 - loss: 0.7271 - val_accuracy: 0.8000 - val_loss: 0.5246\n",
      "Epoch 30/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6583 - loss: 0.7204 - val_accuracy: 0.7980 - val_loss: 0.5027\n",
      "Epoch 31/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6530 - loss: 0.7200 - val_accuracy: 0.8021 - val_loss: 0.5145\n",
      "Epoch 32/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6563 - loss: 0.7204 - val_accuracy: 0.8063 - val_loss: 0.5036\n",
      "Epoch 33/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6617 - loss: 0.7120 - val_accuracy: 0.8130 - val_loss: 0.5019\n",
      "Epoch 34/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6713 - loss: 0.6970 - val_accuracy: 0.7943 - val_loss: 0.5172\n",
      "Epoch 35/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6569 - loss: 0.6937 - val_accuracy: 0.7945 - val_loss: 0.5131\n",
      "Epoch 36/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6513 - loss: 0.6623 - val_accuracy: 0.8188 - val_loss: 0.5110\n",
      "Epoch 37/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6618 - loss: 0.6447 - val_accuracy: 0.8111 - val_loss: 0.4962\n",
      "Epoch 38/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6603 - loss: 0.6374 - val_accuracy: 0.8193 - val_loss: 0.4883\n",
      "Epoch 39/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6575 - loss: 0.6347 - val_accuracy: 0.8198 - val_loss: 0.4832\n",
      "Epoch 40/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6572 - loss: 0.6392 - val_accuracy: 0.8193 - val_loss: 0.4869\n",
      "Epoch 41/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6719 - loss: 0.6093 - val_accuracy: 0.8175 - val_loss: 0.5162\n",
      "Epoch 42/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6643 - loss: 0.6183 - val_accuracy: 0.8096 - val_loss: 0.5053\n",
      "Epoch 43/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6556 - loss: 0.6318 - val_accuracy: 0.8219 - val_loss: 0.4838\n",
      "Epoch 44/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6648 - loss: 0.6118 - val_accuracy: 0.8200 - val_loss: 0.4968\n",
      "Epoch 45/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6589 - loss: 0.6183 - val_accuracy: 0.8236 - val_loss: 0.5083\n",
      "Epoch 46/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6623 - loss: 0.6130 - val_accuracy: 0.8241 - val_loss: 0.5116\n",
      "Epoch 47/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6660 - loss: 0.6100 - val_accuracy: 0.8274 - val_loss: 0.4979\n",
      "Epoch 48/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.6642 - loss: 0.6017 - val_accuracy: 0.8284 - val_loss: 0.5114\n",
      "Epoch 49/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6721 - loss: 0.6037 - val_accuracy: 0.8149 - val_loss: 0.4962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d7ea3c4950>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Capa densa con Dropout\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))  # Dropout para reducir overfitting\n",
    "\n",
    "model.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "# y1_train_encoded = label_encoder.fit_transform(y1_train)\n",
    "# y2_test_encoded = label_encoder.transform(y1_test)\n",
    "model.fit(x1_train,y1_train,epochs=70,batch_size = 128,validation_split = 0.2, callbacks=callbacks.EarlyStopping(patience=10)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,760</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m73,760\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">278,126</span> (1.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m278,126\u001b[0m (1.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">92,708</span> (362.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m92,708\u001b[0m (362.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">185,418</span> (724.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m185,418\u001b[0m (724.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8146 - loss: 0.5198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5098863840103149, 0.8189171552658081]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x1_test, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.81402142, 0.130255  , 0.03421562, 0.0059761 ],\n",
       "       [0.17234664, 0.73742247, 0.15816656, 0.01095618],\n",
       "       [0.01363194, 0.130255  , 0.80503551, 0.01494024],\n",
       "       [0.        , 0.00206754, 0.00258231, 0.96812749]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y1_test, model.predict(x1_test).argmax(axis=1),normalize='pred') #,normalize='pred'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new model performs generally poorer than the baseline, but at least now we're sure that it is more robust as we know now that both train and test include colored images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models/image/baseline_model_a.keras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd model - with rotation, zoom in/out of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three changes are considered from the baseline model:\n",
    "- The accuracies of the train, validation and test (0.67,0.81,0.81) don't seem to signal overfitting. I'll make no use of the Dropout layer\n",
    "- Accuracy musn't be our main metric: we prefer false positives, and rather be extremely sure that the model doesn't miss any alzheimer case.\n",
    "- Lastly, we'll make use of an image data generator, so the model has more differences to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27460, 32, 32, 1)\n",
      "(6058, 32, 32, 1)\n",
      "(27460,)\n",
      "(6058,)\n",
      "[[   0 8704]\n",
      " [   1 7616]\n",
      " [   2 6701]\n",
      " [   3 4439]]\n",
      "[[   0 1920]\n",
      " [   1 1680]\n",
      " [   2 1479]\n",
      " [   3  979]]\n",
      "[[   0 2176]\n",
      " [   1 1904]\n",
      " [   2 1676]\n",
      " [   3 1110]]\n"
     ]
    }
   ],
   "source": [
    "### Datagen with validation split is not supported, so the split must be done prior to the model:\n",
    "x2_train = x1_train\n",
    "x2_test = x1_test\n",
    "y2_train = y1_train\n",
    "y2_test = y1_test\n",
    "x2_train,x2_val,y2_train,y2_val = train_test_split(x2_train,y2_train,test_size=.2,stratify=y2_train,random_state=42)\n",
    "print(x2_train.shape)\n",
    "print(x2_test.shape)\n",
    "print(y2_train.shape)\n",
    "print(y2_test.shape)\n",
    "unique_train, counts_train = np.unique(y2_train, return_counts=True)\n",
    "unique_test, counts_test = np.unique(y2_test, return_counts=True)\n",
    "unique_val, counts_val = np.unique(y2_val, return_counts=True)\n",
    "print(np.asarray((unique_train, counts_train)).T)\n",
    "print(np.asarray((unique_test, counts_test)).T)\n",
    "print(np.asarray((unique_val, counts_val)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 52ms/step - accuracy: 0.3269 - loss: 1.3395 - val_accuracy: 0.3930 - val_loss: 1.2749\n",
      "Epoch 2/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.4027 - loss: 1.2458 - val_accuracy: 0.3456 - val_loss: 1.3052\n",
      "Epoch 3/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.4153 - loss: 1.2297 - val_accuracy: 0.3031 - val_loss: 1.3712\n",
      "Epoch 4/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.4150 - loss: 1.2195 - val_accuracy: 0.4059 - val_loss: 1.2288\n",
      "Epoch 5/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.4306 - loss: 1.1849 - val_accuracy: 0.4800 - val_loss: 1.1496\n",
      "Epoch 6/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.4407 - loss: 1.1663 - val_accuracy: 0.5124 - val_loss: 1.0678\n",
      "Epoch 7/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.4571 - loss: 1.1338 - val_accuracy: 0.5216 - val_loss: 1.0288\n",
      "Epoch 8/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.4622 - loss: 1.1189 - val_accuracy: 0.5629 - val_loss: 0.9566\n",
      "Epoch 9/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.4729 - loss: 1.0994 - val_accuracy: 0.5583 - val_loss: 0.9337\n",
      "Epoch 10/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.4744 - loss: 1.0817 - val_accuracy: 0.5669 - val_loss: 0.9403\n",
      "Epoch 11/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.4787 - loss: 1.0806 - val_accuracy: 0.5613 - val_loss: 0.9408\n",
      "Epoch 12/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.4997 - loss: 1.0427 - val_accuracy: 0.5660 - val_loss: 0.9476\n",
      "Epoch 13/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5104 - loss: 1.0347 - val_accuracy: 0.5792 - val_loss: 0.9036\n",
      "Epoch 14/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5165 - loss: 1.0241 - val_accuracy: 0.5638 - val_loss: 0.9169\n",
      "Epoch 15/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.5174 - loss: 1.0188 - val_accuracy: 0.5609 - val_loss: 0.9027\n",
      "Epoch 16/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.5185 - loss: 1.0132 - val_accuracy: 0.5712 - val_loss: 0.9020\n",
      "Epoch 17/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.5273 - loss: 1.0056 - val_accuracy: 0.5698 - val_loss: 0.9374\n",
      "Epoch 18/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5189 - loss: 0.9976 - val_accuracy: 0.5750 - val_loss: 0.9080\n",
      "Epoch 19/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5382 - loss: 0.9846 - val_accuracy: 0.5964 - val_loss: 0.8521\n",
      "Epoch 20/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5356 - loss: 0.9760 - val_accuracy: 0.5955 - val_loss: 0.8808\n",
      "Epoch 21/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5430 - loss: 0.9637 - val_accuracy: 0.5505 - val_loss: 1.0094\n",
      "Epoch 22/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5418 - loss: 0.9642 - val_accuracy: 0.5969 - val_loss: 0.8353\n",
      "Epoch 23/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5448 - loss: 0.9505 - val_accuracy: 0.5942 - val_loss: 0.8342\n",
      "Epoch 24/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.5437 - loss: 0.9556 - val_accuracy: 0.5931 - val_loss: 0.8547\n",
      "Epoch 25/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.5417 - loss: 0.9533 - val_accuracy: 0.6040 - val_loss: 0.8189\n",
      "Epoch 26/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5459 - loss: 0.9388 - val_accuracy: 0.6123 - val_loss: 0.8019\n",
      "Epoch 27/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5507 - loss: 0.9445 - val_accuracy: 0.6063 - val_loss: 0.8307\n",
      "Epoch 28/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.5596 - loss: 0.9284 - val_accuracy: 0.5824 - val_loss: 0.9401\n",
      "Epoch 29/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5651 - loss: 0.9200 - val_accuracy: 0.5711 - val_loss: 0.9714\n",
      "Epoch 30/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5623 - loss: 0.9211 - val_accuracy: 0.6231 - val_loss: 0.7825\n",
      "Epoch 31/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.5586 - loss: 0.9205 - val_accuracy: 0.5872 - val_loss: 0.8656\n",
      "Epoch 32/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.5603 - loss: 0.9124 - val_accuracy: 0.6063 - val_loss: 0.8451\n",
      "Epoch 33/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5581 - loss: 0.9174 - val_accuracy: 0.6060 - val_loss: 0.8389\n",
      "Epoch 34/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.5600 - loss: 0.9095 - val_accuracy: 0.6311 - val_loss: 0.7770\n",
      "Epoch 35/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5670 - loss: 0.9009 - val_accuracy: 0.5852 - val_loss: 0.8427\n",
      "Epoch 36/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.5679 - loss: 0.9063 - val_accuracy: 0.6097 - val_loss: 0.8129\n",
      "Epoch 37/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5739 - loss: 0.8928 - val_accuracy: 0.6203 - val_loss: 0.8024\n",
      "Epoch 38/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5750 - loss: 0.8924 - val_accuracy: 0.5845 - val_loss: 0.8936\n",
      "Epoch 39/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.5765 - loss: 0.8836 - val_accuracy: 0.6024 - val_loss: 0.8149\n",
      "Epoch 40/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.5672 - loss: 0.8888 - val_accuracy: 0.6105 - val_loss: 0.8299\n",
      "Epoch 41/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5750 - loss: 0.8903 - val_accuracy: 0.6178 - val_loss: 0.8105\n",
      "Epoch 42/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5742 - loss: 0.8825 - val_accuracy: 0.6232 - val_loss: 0.8019\n",
      "Epoch 43/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.5778 - loss: 0.8803 - val_accuracy: 0.6089 - val_loss: 0.8504\n",
      "Epoch 44/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.5766 - loss: 0.8776 - val_accuracy: 0.6267 - val_loss: 0.7727\n",
      "Epoch 45/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.5812 - loss: 0.8719 - val_accuracy: 0.6121 - val_loss: 0.8010\n",
      "Epoch 46/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5777 - loss: 0.8763 - val_accuracy: 0.6183 - val_loss: 0.7944\n",
      "Epoch 47/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5773 - loss: 0.8805 - val_accuracy: 0.6002 - val_loss: 0.8287\n",
      "Epoch 48/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5821 - loss: 0.8740 - val_accuracy: 0.6267 - val_loss: 0.7751\n",
      "Epoch 49/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5835 - loss: 0.8600 - val_accuracy: 0.6235 - val_loss: 0.8000\n",
      "Epoch 50/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.5864 - loss: 0.8640 - val_accuracy: 0.6209 - val_loss: 0.8045\n",
      "Epoch 51/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5774 - loss: 0.8709 - val_accuracy: 0.6154 - val_loss: 0.7656\n",
      "Epoch 52/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.5854 - loss: 0.8620 - val_accuracy: 0.6470 - val_loss: 0.7533\n",
      "Epoch 53/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5806 - loss: 0.8681 - val_accuracy: 0.6360 - val_loss: 0.7768\n",
      "Epoch 54/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5839 - loss: 0.8606 - val_accuracy: 0.6226 - val_loss: 0.7781\n",
      "Epoch 55/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5890 - loss: 0.8590 - val_accuracy: 0.6408 - val_loss: 0.7595\n",
      "Epoch 56/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.5914 - loss: 0.8546 - val_accuracy: 0.6311 - val_loss: 0.8028\n",
      "Epoch 57/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5913 - loss: 0.8533 - val_accuracy: 0.6206 - val_loss: 0.7733\n",
      "Epoch 58/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5906 - loss: 0.8536 - val_accuracy: 0.6388 - val_loss: 0.7655\n",
      "Epoch 59/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5909 - loss: 0.8512 - val_accuracy: 0.6255 - val_loss: 0.7725\n",
      "Epoch 60/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.5930 - loss: 0.8527 - val_accuracy: 0.5865 - val_loss: 0.8048\n",
      "Epoch 61/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5865 - loss: 0.8558 - val_accuracy: 0.6424 - val_loss: 0.7547\n",
      "Epoch 62/70\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.5909 - loss: 0.8452 - val_accuracy: 0.6334 - val_loss: 0.7832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d88043ce30>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = models.Sequential()\n",
    "model2.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "model2.add(layers.Flatten())\n",
    "\n",
    "# Capa densa con Dropout\n",
    "model2.add(layers.Dense(32, activation='relu'))\n",
    "model2.add(layers.Dropout(0.5))  # Dropout para reducir overfitting\n",
    "\n",
    "model2.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# Compilar el modelo\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "# y1_train_encoded = label_encoder.fit_transform(y1_train)\n",
    "# y2_test_encoded = label_encoder.transform(y1_test)\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,  # Rotación aleatoria entre -20 y 20 grados\n",
    "    width_shift_range=0.2,  # Desplazamiento horizontal aleatorio\n",
    "    height_shift_range=0.2,  # Desplazamiento vertical aleatorio\n",
    "    shear_range=0.2,  # Cortes aleatorios\n",
    "    zoom_range=0.2,  # Zoom aleatorio\n",
    "    horizontal_flip=True,  # Volteo horizontal\n",
    "    fill_mode='nearest'  # Rellenar píxeles vacíos con el valor más cercano\n",
    ")\n",
    "model2.fit(datagen.flow(x2_train, y2_train, batch_size=128),epochs=70,validation_data=(x2_val, y2_val), callbacks=callbacks.EarlyStopping(patience=10)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel2\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate(x2_test, y2_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "model2.evaluate(x2_test, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.67056431, 0.28503788, 0.13718245, 0.00344828],\n",
       "       [0.30045755, 0.46212121, 0.27713626, 0.00114943],\n",
       "       [0.02897814, 0.24431818, 0.53718245, 0.00114943],\n",
       "       [0.        , 0.00852273, 0.04849885, 0.99425287]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y2_test, model2.predict(x2_test).argmax(axis=1),normalize='pred') #,normalize='pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save(\"../models/image/model_2.keras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new model predicts in a worse manner, so ImageDataGenerator doesn't seem to be making a positive effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\raulg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.3511 - loss: 1.3023 - val_accuracy: 0.5856 - val_loss: 1.0276\n",
      "Epoch 2/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.4749 - loss: 1.0654 - val_accuracy: 0.6335 - val_loss: 0.8748\n",
      "Epoch 3/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.5108 - loss: 0.9836 - val_accuracy: 0.6649 - val_loss: 0.7888\n",
      "Epoch 4/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.5762 - loss: 0.9281 - val_accuracy: 0.6828 - val_loss: 0.7338\n",
      "Epoch 5/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.5812 - loss: 0.9036 - val_accuracy: 0.6953 - val_loss: 0.7026\n",
      "Epoch 6/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.5985 - loss: 0.8660 - val_accuracy: 0.7183 - val_loss: 0.6705\n",
      "Epoch 7/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6100 - loss: 0.8101 - val_accuracy: 0.7103 - val_loss: 0.6472\n",
      "Epoch 8/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6195 - loss: 0.7923 - val_accuracy: 0.7306 - val_loss: 0.6098\n",
      "Epoch 9/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6328 - loss: 0.7576 - val_accuracy: 0.7368 - val_loss: 0.6093\n",
      "Epoch 10/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6315 - loss: 0.7577 - val_accuracy: 0.7211 - val_loss: 0.6213\n",
      "Epoch 11/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6462 - loss: 0.7393 - val_accuracy: 0.7517 - val_loss: 0.5769\n",
      "Epoch 12/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6536 - loss: 0.7242 - val_accuracy: 0.7517 - val_loss: 0.5599\n",
      "Epoch 13/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6582 - loss: 0.7115 - val_accuracy: 0.7639 - val_loss: 0.5578\n",
      "Epoch 14/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.6632 - loss: 0.7023 - val_accuracy: 0.7415 - val_loss: 0.5716\n",
      "Epoch 15/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.6734 - loss: 0.6877 - val_accuracy: 0.7631 - val_loss: 0.5503\n",
      "Epoch 16/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6745 - loss: 0.6798 - val_accuracy: 0.7767 - val_loss: 0.5225\n",
      "Epoch 17/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.6874 - loss: 0.6636 - val_accuracy: 0.7789 - val_loss: 0.5296\n",
      "Epoch 18/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.6854 - loss: 0.6648 - val_accuracy: 0.7730 - val_loss: 0.5352\n",
      "Epoch 19/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.6869 - loss: 0.6605 - val_accuracy: 0.7798 - val_loss: 0.5199\n",
      "Epoch 20/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.6939 - loss: 0.6474 - val_accuracy: 0.7880 - val_loss: 0.5091\n",
      "Epoch 21/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.6961 - loss: 0.6342 - val_accuracy: 0.7862 - val_loss: 0.4966\n",
      "Epoch 22/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.6967 - loss: 0.6341 - val_accuracy: 0.7759 - val_loss: 0.5360\n",
      "Epoch 23/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7010 - loss: 0.6222 - val_accuracy: 0.7865 - val_loss: 0.5001\n",
      "Epoch 24/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.6997 - loss: 0.6320 - val_accuracy: 0.7896 - val_loss: 0.4963\n",
      "Epoch 25/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7074 - loss: 0.6180 - val_accuracy: 0.7915 - val_loss: 0.4955\n",
      "Epoch 26/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7065 - loss: 0.6120 - val_accuracy: 0.7908 - val_loss: 0.5093\n",
      "Epoch 27/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7042 - loss: 0.6105 - val_accuracy: 0.8076 - val_loss: 0.4650\n",
      "Epoch 28/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7163 - loss: 0.5930 - val_accuracy: 0.7911 - val_loss: 0.4818\n",
      "Epoch 29/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7216 - loss: 0.6017 - val_accuracy: 0.7999 - val_loss: 0.4795\n",
      "Epoch 30/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.7203 - loss: 0.5890 - val_accuracy: 0.8042 - val_loss: 0.4888\n",
      "Epoch 31/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7244 - loss: 0.5793 - val_accuracy: 0.8092 - val_loss: 0.4712\n",
      "Epoch 32/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7338 - loss: 0.5660 - val_accuracy: 0.8033 - val_loss: 0.4616\n",
      "Epoch 33/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7301 - loss: 0.5708 - val_accuracy: 0.8073 - val_loss: 0.4809\n",
      "Epoch 34/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7330 - loss: 0.5729 - val_accuracy: 0.8098 - val_loss: 0.4693\n",
      "Epoch 35/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7527 - loss: 0.5420 - val_accuracy: 0.7943 - val_loss: 0.5241\n",
      "Epoch 36/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7397 - loss: 0.5611 - val_accuracy: 0.8023 - val_loss: 0.4931\n",
      "Epoch 37/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7466 - loss: 0.5446 - val_accuracy: 0.8012 - val_loss: 0.5141\n",
      "Epoch 38/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7452 - loss: 0.5439 - val_accuracy: 0.8098 - val_loss: 0.4919\n",
      "Epoch 39/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7478 - loss: 0.5437 - val_accuracy: 0.8123 - val_loss: 0.4603\n",
      "Epoch 40/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7479 - loss: 0.5473 - val_accuracy: 0.8129 - val_loss: 0.5018\n",
      "Epoch 41/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7540 - loss: 0.5293 - val_accuracy: 0.8161 - val_loss: 0.4889\n",
      "Epoch 42/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7514 - loss: 0.5382 - val_accuracy: 0.8037 - val_loss: 0.5076\n",
      "Epoch 43/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7569 - loss: 0.5260 - val_accuracy: 0.8059 - val_loss: 0.5441\n",
      "Epoch 44/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7578 - loss: 0.5238 - val_accuracy: 0.8112 - val_loss: 0.4619\n",
      "Epoch 45/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7614 - loss: 0.5226 - val_accuracy: 0.8161 - val_loss: 0.4715\n",
      "Epoch 46/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7578 - loss: 0.5204 - val_accuracy: 0.8145 - val_loss: 0.4884\n",
      "Epoch 47/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7737 - loss: 0.5025 - val_accuracy: 0.8029 - val_loss: 0.4836\n",
      "Epoch 48/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7602 - loss: 0.5182 - val_accuracy: 0.8139 - val_loss: 0.4948\n",
      "Epoch 49/70\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7707 - loss: 0.5026 - val_accuracy: 0.8195 - val_loss: 0.4943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d18710c1a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1b = models.Sequential()\n",
    "model1b.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
    "model1b.add(layers.MaxPooling2D((2, 2)))\n",
    "model1b.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model1b.add(layers.MaxPooling2D((2, 2)))\n",
    "model1b.add(layers.Flatten())\n",
    "\n",
    "# Capa densa con Dropout\n",
    "model1b.add(layers.Dense(32, activation='relu'))\n",
    "model1b.add(layers.Dropout(0.5))  # Dropout para reducir overfitting\n",
    "\n",
    "model1b.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# Compilar el modelo\n",
    "model1b.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "# y1_train_encoded = label_encoder.fit_transform(y1_train)\n",
    "# y2_test_encoded = label_encoder.transform(y1_test)\n",
    "model1b.fit(x2_train,y2_train,epochs=70,batch_size = 128,validation_data=(x2_val, y2_val), callbacks=callbacks.EarlyStopping(patience=10)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8498 - loss: 0.4034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3858424425125122, 0.8572136163711548]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1b.evaluate(x2_test, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.857213601848795)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y2_test, model1b.predict(x2_test).argmax(axis=1),average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.76306342, 0.00361011, 0.00231616, 0.        ],\n",
       "       [0.23454328, 0.99638989, 0.1447597 , 0.01409869],\n",
       "       [0.0023933 , 0.        , 0.85292415, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.98590131]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y2_test, model1b.predict(x2_test).argmax(axis=1),normalize='pred') #,normalize='pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.857213601848795)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y2_test, model1b.predict(x2_test).argmax(axis=1),average='weighted') #,normalize='pred'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1b.save(\"../models/image/model_2.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1b = models.load_model(\"../models/image/model_2.keras\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
